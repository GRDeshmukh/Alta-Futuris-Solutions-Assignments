## CNN on SVHN (Street View House Number) dataset

**Please check above svhn_model.ipynb and data_preprocess.ipynb files for building Convolutional Neural Network and data preprocessing.**

The **Street View House Number (SVHN)** is a digit classification benchmark dataset that contains 600000 32Ã—32 RGB images of printed digits (from 0 to 9) cropped from pictures of house number plates. The cropped images are centered in the digit of interest, but nearby digits and other distractors are kept in the image. 

The dataset link is given below.

**Street View House Number(SVHN) Dataset**        **[Link](http://ufldl.stanford.edu/housenumbers/)**

 dataset can be seen as similar in flavor to MNIST (e.g., the images are of small cropped digits), but incorporates an order of magnitude more labeled data (over 600,000 digit images) and comes from a significantly real world problem (recognizing digits and numbers in natural scene images)


## Standard overview for SVHN dataset:

The images lack any contrast normalisation, contain overlapping digits and distracting features which makes it to differ from MNIST.

![download (1)](https://user-images.githubusercontent.com/55298667/133098164-33388ca4-8f8a-4a40-a8c0-04f0bfe1316e.jpg)

It also comes with an additional 531,131 somewhat less difficult samples that can be used as extra training data.

This is the overview in terms of classes, digits for training and testing as well as data formats
1. Total 10 Classes, 1 for each digits  *i.e Label '9' for digit 9 and '10' for digit 0.*
2. For training 73257 digits, For testing 26,032 digits
3. It is available in two different formats
   - Original images with bounding box available for each character (may contain multiple characters in same images).
   - 32x32 cropped images like MNIST having single character in each image.
 



Dataset is obtained from house numbers in Google Street View images. 


Here we are classifying 32 x 32 cropped images given in format 2 

Using CNN architecture.

[Train_32x32](http://ufldl.stanford.edu/housenumbers/train_32x32.mat)                     
[Test_32x32](http://ufldl.stanford.edu/housenumbers/test_32x32.mat)

### Model building and data preprocessing scripts 

   - **`data_preprocess.ipynb`**: preprocess the data
   
   - **`svhn_model.ipynb`**: run the model and report results
    
### New scaled addition
 ```
- Confusion metric 
- Visualization of misclassified and classfied images
```
    
**Dropout rate finding from logs:**
```
From logs we can make out that dropout rate should be higher to learn
good features as images have lots of others digits image pixels also in it.
So it gets confused more often
```

**Consideration and Note:** 
```
I have performed above experiment under 4GB RAM and 1GB GPU Memory.
So it was difficult to train it for more steps, and adding more layers in architecture
```
